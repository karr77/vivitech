import json
import numpy as np
import os
from typing import List, Dict, Any
from pymilvus import (
    connections, 
    Collection, 
    CollectionSchema, 
    FieldSchema, 
    DataType,
    utility,
    db
)
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MilvusDataImporter:
    """Milvusæ•°æ®å¯¼å…¥å™¨"""
    
    def __init__(self, 
                 uri: str = "http://43.140.216.157:18001",
                 token: str = "root:Haipro003838.",
                 db_name: str = "test_data",
                 secure: bool = False):
        """
        åˆå§‹åŒ–Milvusè¿æ¥
        
        Args:
            uri: MilvusæœåŠ¡å™¨åœ°å€
            token: è®¤è¯token
            db_name: æ•°æ®åº“åç§°
            secure: æ˜¯å¦ä½¿ç”¨å®‰å…¨è¿æ¥
        """
        self.uri = uri
        self.token = token
        self.db_name = db_name
        self.secure = secure
        self.connection_alias = "default"
        
        # é›†åˆåç§°
        self.product_collection_name = "xianyu_products"
        self.qa_collection_name = "xianyu_qa_pairs_pairs"
        
        # å‘é‡ç»´åº¦ï¼ˆæ ¹æ®ä¹‹å‰çš„embeddingç»“æœï¼‰
        self.vector_dim = 768
        
        # è¿æ¥åˆ°Milvus
        self.connect_to_milvus()

    def connect_to_milvus(self):
        """è¿æ¥åˆ°Milvusæ•°æ®åº“"""
        try:
            # å»ºç«‹è¿æ¥
            connections.connect(
                alias=self.connection_alias,
                uri=self.uri,
                token=self.token,
                secure=self.secure
            )
            
            # æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“
            if self.db_name not in db.list_database():
                db.create_database(self.db_name)
                logger.info(f"æ•°æ®åº“ {self.db_name} åˆ›å»ºæˆåŠŸ")
            
            # ä½¿ç”¨æŒ‡å®šæ•°æ®åº“
            db.using_database(self.db_name)
            logger.info(f"æˆåŠŸè¿æ¥åˆ°Milvusæ•°æ®åº“: {self.db_name}")
            
        except Exception as e:
            logger.error(f"è¿æ¥Milvuså¤±è´¥: {e}")
            raise

    def create_product_collection_schema(self) -> CollectionSchema:
        """åˆ›å»ºå•†å“é›†åˆçš„Schema"""
        fields = [
            # ä¸»é”®å­—æ®µ
            FieldSchema(
                name="id", 
                dtype=DataType.VARCHAR, 
                max_length=100,
                is_primary=True, 
                auto_id=False,
                description="å•†å“å”¯ä¸€ID"
            ),
            
            # å‘é‡å­—æ®µ
            FieldSchema(
                name="embedding", 
                dtype=DataType.FLOAT_VECTOR, 
                dim=self.vector_dim,
                description="å•†å“embeddingå‘é‡"
            ),
            
            # å•†å“åŸºæœ¬ä¿¡æ¯
            FieldSchema(
                name="title", 
                dtype=DataType.VARCHAR, 
                max_length=500,
                description="å•†å“æ ‡é¢˜"
            ),
            FieldSchema(
                name="description", 
                dtype=DataType.VARCHAR, 
                max_length=2000,
                description="å•†å“æè¿°"
            ),
            FieldSchema(
                name="brand", 
                dtype=DataType.VARCHAR, 
                max_length=100,
                description="å•†å“å“ç‰Œ"
            ),
            FieldSchema(
                name="category", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="å•†å“åˆ†ç±»"
            ),
            FieldSchema(
                name="subcategory", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="å•†å“å­åˆ†ç±»"
            ),
            
            # å•†å“çŠ¶æ€å’Œä»·æ ¼
            FieldSchema(
                name="price", 
                dtype=DataType.DOUBLE,
                description="å•†å“ä»·æ ¼"
            ),
            FieldSchema(
                name="condition", 
                dtype=DataType.VARCHAR, 
                max_length=20,
                description="å•†å“æˆè‰²"
            ),
            FieldSchema(
                name="status", 
                dtype=DataType.VARCHAR, 
                max_length=20,
                description="å•†å“çŠ¶æ€(åœ¨å”®/å·²å”®å‡º/ä¸‹æ¶)"
            ),
            
            # åœ°ç†å’Œç”¨æˆ·ä¿¡æ¯
            FieldSchema(
                name="location", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="å•†å“æ‰€åœ¨åŸå¸‚"
            ),
            FieldSchema(
                name="seller_id", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="å–å®¶ID"
            ),
            
            # ç»Ÿè®¡ä¿¡æ¯
            FieldSchema(
                name="views", 
                dtype=DataType.INT64,
                description="æµè§ˆæ¬¡æ•°"
            ),
            FieldSchema(
                name="likes", 
                dtype=DataType.INT64,
                description="å–œæ¬¢æ¬¡æ•°"
            ),
            
            # æ—¶é—´ä¿¡æ¯
            FieldSchema(
                name="created_at", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="åˆ›å»ºæ—¶é—´"
            ),
            
            # ç”¨äºembeddingçš„æ–‡æœ¬
            FieldSchema(
                name="embedding_text", 
                dtype=DataType.VARCHAR, 
                max_length=2000,
                description="ç”¨äºç”Ÿæˆembeddingçš„æ–‡æœ¬"
            )
        ]
        
        schema = CollectionSchema(
            fields=fields,
            description="é—²é±¼å•†å“ä¿¡æ¯é›†åˆ",
            enable_dynamic_field=True
        )
        
        return schema

    def create_qa_collection_schema(self) -> CollectionSchema:
        """åˆ›å»ºé—®ç­”é›†åˆçš„Schema"""
        fields = [
            # ä¸»é”®å­—æ®µ
            FieldSchema(
                name="id", 
                dtype=DataType.VARCHAR, 
                max_length=100,
                is_primary=True, 
                auto_id=True,
                description="é—®ç­”å¯¹å”¯ä¸€ID"
            ),
            
            # é—®é¢˜å‘é‡å­—æ®µ
            FieldSchema(
                name="question_embedding", 
                dtype=DataType.FLOAT_VECTOR, 
                dim=self.vector_dim,
                description="é—®é¢˜embeddingå‘é‡"
            ),
            
            # ç­”æ¡ˆå‘é‡å­—æ®µ
            FieldSchema(
                name="answer_embedding", 
                dtype=DataType.FLOAT_VECTOR, 
                dim=self.vector_dim,
                description="ç­”æ¡ˆembeddingå‘é‡"
            ),
            
            # å…³è”å•†å“ID
            FieldSchema(
                name="product_id", 
                dtype=DataType.VARCHAR, 
                max_length=100,
                description="å…³è”çš„å•†å“ID"
            ),
            
            # é—®ç­”å†…å®¹
            FieldSchema(
                name="question", 
                dtype=DataType.VARCHAR, 
                max_length=1000,
                description="ç”¨æˆ·é—®é¢˜"
            ),
            FieldSchema(
                name="answer", 
                dtype=DataType.VARCHAR, 
                max_length=1000,
                description="å®¢æœå›ç­”"
            ),
            
            # é—®é¢˜åˆ†ç±»
            FieldSchema(
                name="question_type", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="é—®é¢˜ç±»å‹"
            ),
            
            # æ—¶é—´ä¿¡æ¯
            FieldSchema(
                name="timestamp", 
                dtype=DataType.VARCHAR, 
                max_length=50,
                description="é—®ç­”æ—¶é—´"
            ),
            
            # ç”¨äºembeddingçš„æ–‡æœ¬
            FieldSchema(
                name="question_embedding_text", 
                dtype=DataType.VARCHAR, 
                max_length=1000,
                description="ç”¨äºç”Ÿæˆé—®é¢˜embeddingçš„æ–‡æœ¬"
            ),
            FieldSchema(
                name="answer_embedding_text", 
                dtype=DataType.VARCHAR, 
                max_length=1000,
                description="ç”¨äºç”Ÿæˆç­”æ¡ˆembeddingçš„æ–‡æœ¬"
            )
        ]
        
        schema = CollectionSchema(
            fields=fields,
            description="é—²é±¼é—®ç­”å¯¹é›†åˆ",
            enable_dynamic_field=True
        )
        
        return schema

    def create_collection_if_not_exists(self, collection_name: str, schema: CollectionSchema) -> Collection:
        """æ£€æŸ¥å¹¶åˆ›å»ºé›†åˆ"""
        if utility.has_collection(collection_name):
            logger.info(f"é›†åˆ {collection_name} å·²å­˜åœ¨")
            collection = Collection(collection_name)
        else:
            logger.info(f"åˆ›å»ºé›†åˆ {collection_name}")
            collection = Collection(
                name=collection_name,
                schema=schema,
                using=self.connection_alias
            )
            logger.info(f"é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸ")
        
        return collection

    def create_indexes(self, collection: Collection, is_qa_collection: bool = False):
        """ä¸ºé›†åˆåˆ›å»ºç´¢å¼•"""
        # å‘é‡ç´¢å¼•å‚æ•°
        index_params = {
            "metric_type": "COSINE",  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            "index_type": "IVF_FLAT",
            "params": {"nlist": 1024}
        }
        
        if is_qa_collection:
            # ä¸ºé—®ç­”é›†åˆåˆ›å»ºä¸¤ä¸ªå‘é‡å­—æ®µçš„ç´¢å¼•
            vector_fields = ["question_embedding", "answer_embedding"]
        else:
            # ä¸ºå•†å“é›†åˆåˆ›å»ºå‘é‡ç´¢å¼•
            vector_fields = ["embedding"]
        
        for field in vector_fields:
            # has_indexæ–¹æ³•éœ€è¦æŒ‡å®šindex_nameä½œä¸ºå…³é”®å­—å‚æ•°
            if collection.has_index(timeout=30, index_name=field):
                logger.info(f"ç´¢å¼• {field} å·²å­˜åœ¨")
            else:
                logger.info(f"ä¸ºå­—æ®µ {field} åˆ›å»ºç´¢å¼•...")
                collection.create_index(
                    field_name=field,
                    index_params=index_params,
                    timeout=30
                )
                logger.info(f"å­—æ®µ {field} ç´¢å¼•åˆ›å»ºå®Œæˆ")

    def load_embedding_data(self, data_dir: str = "embeddings_data") -> tuple:
        """åŠ è½½embeddingæ•°æ®"""
        logger.info(f"ä» {data_dir} åŠ è½½embeddingæ•°æ®...")
        
        # åŠ è½½å‘é‡æ•°æ®
        product_embeddings = np.load(os.path.join(data_dir, "product_embeddings.npy"))
        question_embeddings = np.load(os.path.join(data_dir, "question_embeddings.npy"))
        answer_embeddings = np.load(os.path.join(data_dir, "answer_embeddings.npy"))
        
        # åŠ è½½å¤„ç†åçš„æ•°æ®
        with open(os.path.join(data_dir, "processed_products.json"), 'r', encoding='utf-8') as f:
            processed_products = json.load(f)
        
        with open(os.path.join(data_dir, "processed_qa_pairs.json"), 'r', encoding='utf-8') as f:
            processed_qa_pairs = json.load(f)
        
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: {len(processed_products)}ä¸ªå•†å“, {len(processed_qa_pairs)}ä¸ªé—®ç­”å¯¹")
        
        return (
            product_embeddings, question_embeddings, answer_embeddings,
            processed_products, processed_qa_pairs
        )

    def prepare_product_data(self, processed_products: List[Dict], product_embeddings: np.ndarray) -> List[List]:
        """å‡†å¤‡å•†å“æ•°æ®ç”¨äºæ’å…¥"""
        logger.info("å‡†å¤‡å•†å“æ•°æ®...")
        
        # æŒ‰å­—æ®µç»„ç»‡æ•°æ®
        data = [
            [product["id"] for product in processed_products],  # id
            product_embeddings.tolist(),  # embedding
            [product["title"] for product in processed_products],  # title
            [product["description"] for product in processed_products],  # description
            [product["brand"] for product in processed_products],  # brand
            [product["category"] for product in processed_products],  # category
            [product["subcategory"] for product in processed_products],  # subcategory
            [float(product["price"]) for product in processed_products],  # price
            [product["condition"] for product in processed_products],  # condition
            [product["status"] for product in processed_products],  # status
            [product["location"] for product in processed_products],  # location
            [product["seller_id"] for product in processed_products],  # seller_id
            [int(product["views"]) for product in processed_products],  # views
            [int(product["likes"]) for product in processed_products],  # likes
            [product["created_at"] for product in processed_products],  # created_at
            [product["embedding_text"] for product in processed_products],  # embedding_text
        ]
        
        logger.info(f"å•†å“æ•°æ®å‡†å¤‡å®Œæˆ: {len(data[0])} æ¡è®°å½•")
        return data

    def prepare_qa_data(self, processed_qa_pairs: List[Dict], 
                       question_embeddings: np.ndarray, 
                       answer_embeddings: np.ndarray) -> List[List]:
        """å‡†å¤‡é—®ç­”æ•°æ®ç”¨äºæ’å…¥"""
        logger.info("å‡†å¤‡é—®ç­”æ•°æ®...")
        
        # æŒ‰å­—æ®µç»„ç»‡æ•°æ®ï¼ˆæ³¨æ„ï¼šidå­—æ®µæ˜¯auto_idï¼Œä¸éœ€è¦æä¾›ï¼‰
        data = [
            question_embeddings.tolist(),  # question_embedding
            answer_embeddings.tolist(),  # answer_embedding
            [qa["product_id"] for qa in processed_qa_pairs],  # product_id
            [qa["question"] for qa in processed_qa_pairs],  # question
            [qa["answer"] for qa in processed_qa_pairs],  # answer
            [qa["question_type"] for qa in processed_qa_pairs],  # question_type
            [qa["timestamp"] for qa in processed_qa_pairs],  # timestamp
            [qa["question_embedding_text"] for qa in processed_qa_pairs],  # question_embedding_text
            [qa["answer_embedding_text"] for qa in processed_qa_pairs],  # answer_embedding_text
        ]
        
        logger.info(f"é—®ç­”æ•°æ®å‡†å¤‡å®Œæˆ: {len(data[0])} æ¡è®°å½•")
        return data

    def insert_data(self, collection: Collection, data: List[List], batch_size: int = 100):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        total_records = len(data[0])
        logger.info(f"å¼€å§‹æ’å…¥æ•°æ®ï¼Œæ€»è®¡ {total_records} æ¡è®°å½•")
        
        inserted_count = 0
        
        for i in range(0, total_records, batch_size):
            end_idx = min(i + batch_size, total_records)
            
            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            batch_data = []
            for field_data in data:
                batch_data.append(field_data[i:end_idx])
            
            # æ’å…¥æ•°æ®
            insert_result = collection.insert(batch_data)
            inserted_count += len(insert_result.primary_keys)
            
            logger.info(f"å·²æ’å…¥ {inserted_count}/{total_records} æ¡è®°å½•")
        
        # åˆ·æ–°æ•°æ®
        collection.flush()
        logger.info(f"æ•°æ®æ’å…¥å®Œæˆï¼Œæ€»è®¡ {inserted_count} æ¡è®°å½•")
        
        return inserted_count

    def verify_data_integrity(self, collection: Collection, expected_count: int):
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        logger.info("éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        
        # è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
        collection.load()
        actual_count = collection.num_entities
        
        logger.info(f"æœŸæœ›è®°å½•æ•°: {expected_count}")
        logger.info(f"å®é™…è®°å½•æ•°: {actual_count}")
        
        if actual_count == expected_count:
            logger.info("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
            return True
        else:
            logger.error("âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥")
            return False

    def import_all_data(self, data_dir: str = "embeddings_data"):
        """å¯¼å…¥æ‰€æœ‰æ•°æ®çš„ä¸»å‡½æ•°"""
        try:
            # 1. åŠ è½½embeddingæ•°æ®
            (product_embeddings, question_embeddings, answer_embeddings,
             processed_products, processed_qa_pairs) = self.load_embedding_data(data_dir)
            
            # 2. åˆ›å»ºå•†å“é›†åˆ
            product_schema = self.create_product_collection_schema()
            product_collection = self.create_collection_if_not_exists(
                self.product_collection_name, product_schema
            )
            
            # 3. åˆ›å»ºé—®ç­”é›†åˆ
            qa_schema = self.create_qa_collection_schema()
            qa_collection = self.create_collection_if_not_exists(
                self.qa_collection_name, qa_schema
            )
            
            # 4. åˆ›å»ºç´¢å¼•
            self.create_indexes(product_collection, is_qa_collection=False)
            self.create_indexes(qa_collection, is_qa_collection=True)
            
            # 5. å‡†å¤‡å¹¶æ’å…¥å•†å“æ•°æ®
            if product_collection.num_entities == 0:
                logger.info("æ’å…¥å•†å“æ•°æ®...")
                product_data = self.prepare_product_data(processed_products, product_embeddings)
                self.insert_data(product_collection, product_data)
                self.verify_data_integrity(product_collection, len(processed_products))
            else:
                logger.info(f"å•†å“é›†åˆå·²æœ‰ {product_collection.num_entities} æ¡è®°å½•ï¼Œè·³è¿‡æ’å…¥")
            
            # 6. å‡†å¤‡å¹¶æ’å…¥é—®ç­”æ•°æ®
            if qa_collection.num_entities == 0:
                logger.info("æ’å…¥é—®ç­”æ•°æ®...")
                qa_data = self.prepare_qa_data(processed_qa_pairs, question_embeddings, answer_embeddings)
                self.insert_data(qa_collection, qa_data)
                self.verify_data_integrity(qa_collection, len(processed_qa_pairs))
            else:
                logger.info(f"é—®ç­”é›†åˆå·²æœ‰ {qa_collection.num_entities} æ¡è®°å½•ï¼Œè·³è¿‡æ’å…¥")
            
            # 7. åŠ è½½é›†åˆåˆ°å†…å­˜
            product_collection.load()
            qa_collection.load()
            
            logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®å¯¼å…¥å®Œæˆï¼")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            self.print_statistics(product_collection, qa_collection)
            
        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å…¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            raise

    def print_statistics(self, product_collection: Collection, qa_collection: Collection):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š Milvusæ•°æ®åº“å¯¼å…¥ç»Ÿè®¡")
        print("="*60)
        print(f"ğŸ—„ï¸  æ•°æ®åº“åç§°: {self.db_name}")
        print(f"ğŸ”— è¿æ¥åœ°å€: {self.uri}")
        print(f"ğŸ“¦ å•†å“é›†åˆ: {self.product_collection_name}")
        print(f"   - è®°å½•æ•°: {product_collection.num_entities}")
        print(f"   - å‘é‡ç»´åº¦: {self.vector_dim}")
        print(f"â“ é—®ç­”é›†åˆ: {self.qa_collection_name}")
        print(f"   - è®°å½•æ•°: {qa_collection.num_entities}")
        print(f"   - å‘é‡ç»´åº¦: {self.vector_dim}")
        print(f"â° å¯¼å…¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)

    def test_search(self, query_text: str = "iPhoneæ‰‹æœº", top_k: int = 3):
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        logger.info(f"æµ‹è¯•æœç´¢: '{query_text}'")
        
        try:
            # è¿™é‡Œéœ€è¦é‡æ–°ç”Ÿæˆqueryçš„embeddingï¼Œä½†ç®€åŒ–èµ·è§å…ˆè·³è¿‡
            # å®é™…ä½¿ç”¨æ—¶éœ€è¦åŠ è½½embeddingæ¨¡å‹
            logger.info("æœç´¢åŠŸèƒ½æµ‹è¯•éœ€è¦åŠ è½½embeddingæ¨¡å‹ï¼Œæš‚æ—¶è·³è¿‡")
            
        except Exception as e:
            logger.error(f"æœç´¢æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡æˆ–ç›´æ¥é…ç½®è¿æ¥ä¿¡æ¯
    importer = MilvusDataImporter(
        uri="http://43.140.216.157:18001",
        token="root:Haipro003838.",
        db_name="test_data",
        secure=False
    )
    
    try:
        # å¯¼å…¥æ‰€æœ‰æ•°æ®
        importer.import_all_data("embeddings_data")
        
        # ç®€å•æµ‹è¯•ï¼ˆéœ€è¦embeddingæ¨¡å‹æ‰èƒ½å®Œæ•´æµ‹è¯•ï¼‰
        # importer.test_search("iPhoneæ‰‹æœº")
        
        logger.info("âœ… æ‰€æœ‰æ“ä½œå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()